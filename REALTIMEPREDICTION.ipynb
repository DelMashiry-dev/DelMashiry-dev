{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNuCuliyFhHvRTHSt1LLzSq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DelMashiry-dev/DelMashiry-dev/blob/main/REALTIMEPREDICTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount the Drive Containing the folder with the dataset\n"
      ],
      "metadata": {
        "id": "3XNhqck_8qBE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mn2iL5XOsX2q"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Medical_Resource_Prediction"
      ],
      "metadata": {
        "id": "dS_F3YEd8-PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Read first 100000 rows but only specific columns\n",
        "df = pd.read_csv('/content/drive/MyDrive/Medical_Resource_Prediction/owid-covid-data.csv', nrows=100000, usecols=['iso_code', 'continent', 'location', 'date','total_cases', 'new_cases', 'total_deaths', 'new_deaths', 'reproduction_rate',\n",
        "    'icu_patients', 'hosp_patients', 'weekly_icu_admissions', 'weekly_hosp_admissions','total_vaccinations', 'people_vaccinated', 'people_fully_vaccinated', 'new_vaccinations',\n",
        "    'total_tests', 'new_tests', 'positive_rate','population', 'population_density', 'median_age', 'aged_65_older', 'aged_70_older','cardiovasc_death_rate', 'diabetes_prevalence'])\n",
        "df.fillna(0, inplace=True)\n",
        "from IPython.display import display\n",
        "display(df.head(5000))"
      ],
      "metadata": {
        "id": "QuDpWswZ9M7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identify Relevant Features\n",
        "\n"
      ],
      "metadata": {
        "id": "WPsVjR0QHI5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "relevant_columns = [\n",
        "    'iso_code', 'continent', 'location', 'date','total_cases', 'new_cases', 'total_deaths', 'new_deaths', 'reproduction_rate',\n",
        "    'icu_patients', 'hosp_patients', 'weekly_icu_admissions', 'weekly_hosp_admissions','total_vaccinations', 'people_vaccinated', 'people_fully_vaccinated', 'new_vaccinations',\n",
        "    'total_tests', 'new_tests', 'positive_rate', 'population', 'population_density', 'median_age', 'aged_65_older', 'aged_70_older',\n",
        "    'hospital_beds_per_thousand', 'cardiovasc_death_rate', 'diabetes_prevalence'\n",
        "]"
      ],
      "metadata": {
        "id": "sGi9QlQX-MeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning\n",
        "# Remove Irrelevant Columns\n",
        "# Filter the dataset to keep only the selected columns:\n",
        "\n"
      ],
      "metadata": {
        "id": "sZvVPoCJHlcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Medical_Resource_Prediction/owid-covid-data.csv')\n",
        "\n",
        "# Keep relevant columns\n",
        "df = df[relevant_columns]\n",
        "from IPython.display import display\n",
        "display(df.head(5))"
      ],
      "metadata": {
        "id": "T6xM4ZywHBCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handle Missing Values\n",
        "\n"
      ],
      "metadata": {
        "id": "7-s6Zoe8OtQO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imputation Strategy\n",
        "\n"
      ],
      "metadata": {
        "id": "TnBflW_6PSMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert date to datetime\n",
        "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "\n",
        "# Drop rows with missing iso_code, location, or date\n",
        "df = df.dropna(subset=['iso_code', 'location', 'date'])\n",
        "\n",
        "# Time-series imputation for disease and healthcare metrics\n",
        "time_series_cols = [\n",
        "    'total_cases', 'new_cases', 'total_deaths', 'new_deaths', 'reproduction_rate',\n",
        "    'icu_patients', 'hosp_patients', 'weekly_icu_admissions', 'weekly_hosp_admissions',\n",
        "    'total_vaccinations', 'people_vaccinated', 'people_fully_vaccinated', 'new_vaccinations',\n",
        "    'total_tests', 'new_tests', 'positive_rate'\n",
        "]\n",
        "for col in time_series_cols:\n",
        "    df[col] = df.groupby('location')[col].fillna(method='ffill').interpolate()\n",
        "\n",
        "# Zero imputation for ICU/hospital metrics if still missing (early outbreak)\n",
        "zero_impute_cols = ['icu_patients', 'hosp_patients', 'weekly_icu_admissions', 'weekly_hosp_admissions']\n",
        "df[zero_impute_cols] = df[zero_impute_cols].fillna(0)\n",
        "\n",
        "# Median imputation for demographic/healthcare capacity features\n",
        "median_impute_cols = [\n",
        "    'population_density', 'median_age', 'aged_65_older', 'aged_70_older',\n",
        "    'hospital_beds_per_thousand', 'cardiovasc_death_rate', 'diabetes_prevalence'\n",
        "]\n",
        "for col in median_impute_cols:\n",
        "    df[col] = df.groupby('continent')[col].transform(lambda x: x.fillna(x.median()))\n",
        "\n",
        "# Handle remaining missing values (if any) with global median\n",
        "for col in median_impute_cols:\n",
        "    df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "    display(df.head(5000))"
      ],
      "metadata": {
        "id": "5DYyaRJUPOAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check for Outliers\n",
        "\n"
      ],
      "metadata": {
        "id": "dOsasCkLQ_80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in time_series_cols:\n",
        "    df[col] = df.groupby('location')[col].transform(lambda x: x.clip(upper=x.quantile(0.99)))"
      ],
      "metadata": {
        "id": "btD1MD2mQm1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering\n",
        "\n"
      ],
      "metadata": {
        "id": "cUv15i1gSaMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lag features\n",
        "for col in ['new_cases', 'icu_patients', 'hosp_patients']:\n",
        "    df[f'{col}_lag7'] = df.groupby('location')[col].shift(7)\n",
        "    df[f'{col}_lag14'] = df.groupby('location')[col].shift(14)\n",
        "\n",
        "# Rolling averages\n",
        "df['new_cases_7d_avg'] = df.groupby('location')['new_cases'].rolling(7, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "df['new_deaths_7d_avg'] = df.groupby('location')['new_deaths'].rolling(7, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "\n",
        "# Proxy for ventilator demand (e.g., 50% of ICU patients)\n",
        "df['ventilator_demand'] = df['icu_patients'] * 0.5"
      ],
      "metadata": {
        "id": "YrmyYucOSbWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Dataset\n",
        "# Ensure the dataset is sorted by location and date for time-series modeling:\n",
        "\n"
      ],
      "metadata": {
        "id": "_gOpF9z1Sk-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sort_values(['location', 'date'])"
      ],
      "metadata": {
        "id": "JPTN4YbsSvgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rZg7_k9MUyL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "0IP9Nu9KVAI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time Series Plot Example (Plotly)\n",
        "\n"
      ],
      "metadata": {
        "id": "IMNV5JJZWvv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This creates an interactive line plot where you can hover over points to see exact values, zoom in on specific time periods, and compare trends across locations. This is particularly useful for understanding temporal patterns in disease progression and resource demand\n",
        "\n"
      ],
      "metadata": {
        "id": "9cEWtVh0W3se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Plot multiple metrics over time, colored by location\n",
        "fig = px.line(df, x='date', y=['total_cases', 'new_cases', 'icu_patients'], color='location', title='Key Metrics Over Time')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "hxuZD5i2VtNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scatter Plot Example (Seaborn)\n",
        "\n"
      ],
      "metadata": {
        "id": "PTXBiGPEYBAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot total_cases vs. icu_patients, colored by location\n",
        "sns.scatterplot(data=df, x='total_cases', y='icu_patients', hue='location')\n",
        "plt.title('Total Cases vs. ICU Patients')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MsvbTQNjYGG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This scatter plot helps visualize the relationship between disease spread and ICU demand, which is a proxy for ventilator and medical personnel needs. You can extend this to plot total_vaccinations vs. new_cases to assess vaccination impact.\n",
        "\n"
      ],
      "metadata": {
        "id": "DhbVDd31bdyZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlation Heatmap (Seaborn)\n",
        "\n"
      ],
      "metadata": {
        "id": "Su5OcILlecmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Select numeric columns for correlation\n",
        "numeric_df = df.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Compute and plot correlation heatmap\n",
        "plt.figure(figsize=(40, 38))\n",
        "sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xZVAAg6Hbe3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#This heatmap shows correlations between all numeric features, helping identify which factors (e.g., population_density, median_age) are most related to resource demand\n",
        "\n"
      ],
      "metadata": {
        "id": "u5-RZ06-e8KH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bar Chart(Plotly)\n",
        "\n"
      ],
      "metadata": {
        "id": "PPHRjxWyfIdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Get the latest data for each location\n",
        "latest_df = df[df['date'] == df['date'].max()]\n",
        "\n",
        "# Create bar chart for latest total_cases\n",
        "fig = px.bar(latest_df, x='location', y='total_cases', title='Latest Total Cases by Location')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "2PjogA40fD8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#This bar chart compares the most recent total cases across locations, which can help identify regions with high demand for real-time monitoring\n",
        "\n"
      ],
      "metadata": {
        "id": "t0YEAjdDgV62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Get the latest data for each location\n",
        "latest_df = df[df['date'] == df['date'].max()]\n",
        "\n",
        "# Sort by total cases in descending order\n",
        "latest_df = latest_df.sort_values(by='total_cases', ascending=False)\n",
        "\n",
        "# Create a horizontal bar chart with color by continent\n",
        "fig = px.bar(latest_df, x='total_cases', y='location', color='continent', orientation='h',\n",
        "             title='Latest Total Cases by Location, Colored by Continent')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "_9uC9uSsfuSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Geographic Map (Plotly)\n",
        "\n"
      ],
      "metadata": {
        "id": "myJmcwMsgdlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Create choropleth map for total_cases by country, animated over time\n",
        "fig = px.choropleth(df, locations='iso_code', locationmode='ISO-3', color='total_cases', hover_name='location', animation_frame='date', title='Total Cases Over Time by Country')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "m7Bg8bA2gGjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This animated map shows the spatial distribution of total cases over time, which is useful for understanding regional disparities and can be sourced from real-time APIs like OWID\n",
        "\n"
      ],
      "metadata": {
        "id": "YRcrq8XAhq8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# Assuming your cleaned DataFrame is named 'df_clean'\n",
        "# If not, replace with your actual cleaned DataFrame name\n",
        "\n",
        "def display_final_dataset(df, num_rows=5, all_columns=False):\n",
        "    \"\"\"\n",
        "    Displays the final prepared dataset in a clean table format\n",
        "\n",
        "    Parameters:\n",
        "    - df: Your cleaned DataFrame\n",
        "    - num_rows: Number of rows to display (default: 5)\n",
        "    - all_columns: Whether to show all columns (default: False for truncated view)\n",
        "    \"\"\"\n",
        "\n",
        "    # Configure display options\n",
        "    pd.set_option('display.max_columns', None if all_columns else 10)\n",
        "    pd.set_option('display.width', 1000)\n",
        "    pd.set_option('display.max_colwidth', 20)\n",
        "\n",
        "    # Create a styled table\n",
        "    styled_df = (df.head(num_rows)\n",
        "                 .style\n",
        "                 .set_properties(**{'text-align': 'center'})\n",
        "                 .set_table_styles([{\n",
        "                     'selector': 'th',\n",
        "                     'props': [('background-color', '#40466e'),\n",
        "                              ('color', 'white'),\n",
        "                              ('font-weight', 'bold')]\n",
        "                 }])\n",
        "                 .background_gradient(cmap='Blues', subset=df.select_dtypes(include='number').columns)\n",
        "                 .format(None, na_rep=\"NA\"))\n",
        "\n",
        "    # Display in notebook\n",
        "    display(styled_df)\n",
        "\n",
        "    # Show dataset info\n",
        "    print(\"\\n\\033[1mDataset Summary:\\033[0m\")\n",
        "    print(f\"Total Rows: {len(df):,}\")\n",
        "    print(f\"Total Columns: {len(df.columns)}\")\n",
        "    print(\"\\n\\033[1mColumn Types:\\033[0m\")\n",
        "    print(df.dtypes.value_counts())\n",
        "\n",
        "    # Show NA counts if any exist\n",
        "    if df.isna().sum().sum() > 0:\n",
        "        print(\"\\n\\033[1mMissing Values:\\033[0m\")\n",
        "        missing = df.isna().sum()[df.isna().sum() > 0]\n",
        "        print(missing)\n",
        "    else:\n",
        "        print(\"\\n\\033[1mNo missing values found!\\033[0m\")\n",
        "\n",
        "# Usage - call the function with your cleaned DataFrame\n",
        "display_final_dataset(df, num_rows=5, all_columns=True)"
      ],
      "metadata": {
        "id": "qSGGYLCtpVWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "\n",
        "def display_and_export_dataset(df, num_rows=5, export_name=\"cleaned_dataset\"):\n",
        "    \"\"\"\n",
        "    Displays the final dataset with enhanced formatting and export options\n",
        "\n",
        "    Parameters:\n",
        "    - df: Your cleaned DataFrame\n",
        "    - num_rows: Number of rows to display\n",
        "    - export_name: Base name for exported files\n",
        "    \"\"\"\n",
        "\n",
        "    # ==============================================\n",
        "    # 1. SPECIAL COLUMN FORMATTING\n",
        "    # ==============================================\n",
        "    format_rules = {\n",
        "        # Medical resource columns (integers with comma separators)\n",
        "        r'(beds|patients|ventilators|staff|ppe)': '{:,.0f}',\n",
        "\n",
        "        # Percentage columns (show as % with 1 decimal)\n",
        "        r'(rate|ratio|percent|per_hundred)': '{:.1%}',\n",
        "\n",
        "        # Date columns (standard date format)\n",
        "        'date': '{:%Y-%m-%d}',\n",
        "\n",
        "        # Small decimal numbers (3 decimal places)\n",
        "        r'(growth|factor|index)': '{:.3f}'\n",
        "    }\n",
        "\n",
        "    # ==============================================\n",
        "    # 2. CREATE STYLED TABLE\n",
        "    # ==============================================\n",
        "    styler = (df.head(num_rows)\n",
        "              .style\n",
        "              .set_properties(**{'text-align': 'center'})\n",
        "              .set_table_styles([{\n",
        "                  'selector': 'th',\n",
        "                  'props': [\n",
        "                      ('background-color', '#2a3f5f'),\n",
        "                      ('color', 'white'),\n",
        "                      ('font-weight', 'bold'),\n",
        "                      ('position', 'sticky'),\n",
        "                      ('top', '0')\n",
        "                  ]\n",
        "              }]))\n",
        "\n",
        "    # Apply special formatting\n",
        "    for regex, formatter in format_rules.items():\n",
        "        cols = df.filter(regex=regex, axis=1).columns\n",
        "        if not cols.empty:\n",
        "            styler.format(formatter, subset=cols)\n",
        "\n",
        "    # Highlight important metrics\n",
        "    medical_cols = df.filter(regex='icu|hosp|ventilator|ppe').columns\n",
        "    if not medical_cols.empty:\n",
        "        styler.background_gradient(\n",
        "            cmap='YlOrRd',\n",
        "            subset=medical_cols,\n",
        "            vmin=0, vmax=df[medical_cols].max().max()\n",
        "        )\n",
        "\n",
        "    # ==============================================\n",
        "    # 3. DISPLAY RESULTS\n",
        "    # ==============================================\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\033[1m{'CLEANED DATASET PREVIEW':^80}\\033[0m\")\n",
        "    print(\"=\"*80)\n",
        "    display(styler)\n",
        "\n",
        "    # ==============================================\n",
        "    # 4. STATISTICAL SUMMARIES\n",
        "    # ==============================================\n",
        "    print(\"\\n\\033[1mSTATISTICAL SUMMARIES\\033[0m\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    # Numeric columns summary\n",
        "    numeric_df = df.select_dtypes(include=np.number)\n",
        "    if not numeric_df.empty:\n",
        "        print(\"\\n\\033[4mNumeric Columns:\\033[0m\")\n",
        "        display(numeric_df.describe().style.format(\"{:.2f}\"))\n",
        "\n",
        "    # Categorical columns summary\n",
        "    categorical_df = df.select_dtypes(include='object')\n",
        "    if not categorical_df.empty:\n",
        "        print(\"\\n\\033[4mCategorical Columns:\\033[0m\")\n",
        "        for col in categorical_df.columns:\n",
        "            print(f\"\\n• {col}:\")\n",
        "            print(df[col].value_counts(dropna=False).head())\n",
        "\n",
        "    # ==============================================\n",
        "    # 5. EXPORT OPTIONS\n",
        "    # ==============================================\n",
        "    print(\"\\n\\033[1mEXPORT OPTIONS\\033[0m\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    try:\n",
        "        # Excel Export\n",
        "        excel_file = f\"{export_name}.xlsx\"\n",
        "        with pd.ExcelWriter(excel_file, engine='xlsxwriter') as writer:\n",
        "            df.to_excel(writer, sheet_name='Data', index=False)\n",
        "\n",
        "            # Add summary sheets\n",
        "            numeric_df.describe().to_excel(writer, sheet_name='Numeric Summary')\n",
        "            if not categorical_df.empty:\n",
        "                pd.concat([\n",
        "                    df[col].value_counts(dropna=False).rename(col)\n",
        "                    for col in categorical_df.columns\n",
        "                ], axis=1).to_excel(writer, sheet_name='Category Counts')\n",
        "\n",
        "            # Get workbook objects\n",
        "            workbook = writer.book\n",
        "            worksheet = writer.sheets['Data']\n",
        "\n",
        "            # Add Excel formatting\n",
        "            header_format = workbook.add_format({\n",
        "                'bold': True,\n",
        "                'text_wrap': True,\n",
        "                'valign': 'top',\n",
        "                'fg_color': '#2a3f5f',\n",
        "                'font_color': 'white',\n",
        "                'border': 1\n",
        "            })\n",
        "\n",
        "            # Apply header format\n",
        "            for col_num, value in enumerate(df.columns.values):\n",
        "                worksheet.write(0, col_num, value, header_format)\n",
        "\n",
        "            # Auto-adjust column widths\n",
        "            for i, col in enumerate(df.columns):\n",
        "                max_len = max((\n",
        "                    df[col].astype(str).map(len).max(),  # Data length\n",
        "                    len(str(col))  # Header length\n",
        "                )) + 2\n",
        "                worksheet.set_column(i, i, min(max_len, 50))\n",
        "\n",
        "        print(f\"✓ Excel file saved as: {excel_file}\")\n",
        "\n",
        "        # HTML Export\n",
        "        html_file = f\"{export_name}.html\"\n",
        "        styler.to_html(html_file)\n",
        "        print(f\"✓ HTML file saved as: {html_file}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Export failed: {str(e)}\")\n",
        "\n",
        "# Usage example:\n",
        "# display_and_export_dataset(df_clean, num_rows=10, export_name=\"medical_resources\")"
      ],
      "metadata": {
        "id": "qvd-x0zHrkNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_and_export_dataset(df,\n",
        "                         num_rows=10,\n",
        "                         export_name=\"my_cleaned_data\")"
      ],
      "metadata": {
        "id": "TS2u6cTZv7Ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xlsxwriter\n"
      ],
      "metadata": {
        "id": "B1KJk5dTw7PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "\n",
        "def display_and_export_dataset(df, num_rows=5, export_name=\"cleaned_dataset\"):\n",
        "    \"\"\"\n",
        "    Displays the final dataset with enhanced formatting and export options\n",
        "\n",
        "    Parameters:\n",
        "    - df: Your cleaned DataFrame\n",
        "    - num_rows: Number of rows to display\n",
        "    - export_name: Base name for exported files\n",
        "    \"\"\"\n",
        "\n",
        "    # ==============================================\n",
        "    # 1. SPECIAL COLUMN FORMATTING\n",
        "    # ==============================================\n",
        "    format_rules = {\n",
        "        # Medical resource columns\n",
        "        r'(beds|patients|ventilators|staff|ppe)': '{:,.0f}',\n",
        "        # Percentage columns\n",
        "        r'(rate|ratio|percent|per_hundred)': '{:.1%}',\n",
        "        # Date columns\n",
        "        'date': '{:%Y-%m-%d}',\n",
        "        # Small decimal numbers\n",
        "        r'(growth|factor|index)': '{:.3f}'\n",
        "    }\n",
        "\n",
        "    # ==============================================\n",
        "    # 2. CREATE STYLED TABLE\n",
        "    # ==============================================\n",
        "    styler = (df.head(num_rows)\n",
        "              .style\n",
        "              .set_properties(**{'text-align': 'center'})\n",
        "              .set_table_styles([{\n",
        "                  'selector': 'th',\n",
        "                  'props': [\n",
        "                      ('background-color', '#2a3f5f'),\n",
        "                      ('color', 'white'),\n",
        "                      ('font-weight', 'bold')\n",
        "                  ]\n",
        "              }]))\n",
        "\n",
        "    # Apply formatting\n",
        "    for regex, formatter in format_rules.items():\n",
        "        cols = df.filter(regex=regex, axis=1).columns\n",
        "        if not cols.empty:\n",
        "            styler.format(formatter, subset=cols)\n",
        "\n",
        "    # Highlight medical metrics\n",
        "    medical_cols = df.filter(regex='icu|hosp|ventilator|ppe').columns\n",
        "    if not medical_cols.empty:\n",
        "        styler.background_gradient(\n",
        "            cmap='YlOrRd',\n",
        "            subset=medical_cols,\n",
        "            vmin=0, vmax=df[medical_cols].max().max()\n",
        "        )\n",
        "\n",
        "    # ==============================================\n",
        "    # 3. DISPLAY RESULTS\n",
        "    # ==============================================\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\033[1m{'CLEANED DATASET PREVIEW':^80}\\033[0m\")\n",
        "    print(\"=\"*80)\n",
        "    display(styler)\n",
        "\n",
        "    # ==============================================\n",
        "    # 4. STATISTICAL SUMMARIES\n",
        "    # ==============================================\n",
        "    print(\"\\n\\033[1mSTATISTICAL SUMMARIES\\033[0m\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    # Numeric summary\n",
        "    numeric_df = df.select_dtypes(include=np.number)\n",
        "    if not numeric_df.empty:\n",
        "        print(\"\\n\\033[4mNumeric Columns:\\033[0m\")\n",
        "        display(numeric_df.describe().style.format(\"{:.2f}\"))\n",
        "\n",
        "    # Categorical summary\n",
        "    categorical_df = df.select_dtypes(include='object')\n",
        "    if not categorical_df.empty:\n",
        "        print(\"\\n\\033[4mCategorical Columns:\\033[0m\")\n",
        "        for col in categorical_df.columns:\n",
        "            print(f\"\\n• {col}:\")\n",
        "            print(df[col].value_counts(dropna=False).head())\n",
        "\n",
        "    # ==============================================\n",
        "    # 5. EXPORT OPTIONS\n",
        "    # ==============================================\n",
        "    print(\"\\n\\033[1mEXPORT OPTIONS\\033[0m\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    # HTML Export (always available)\n",
        "    html_file = f\"{export_name}.html\"\n",
        "    styler.to_html(html_file)\n",
        "    print(f\"✓ HTML file saved as: {html_file}\")\n",
        "\n",
        "    # Excel Export (only if xlsxwriter is available)\n",
        "    try:\n",
        "        import xlsxwriter\n",
        "        excel_file = f\"{export_name}.xlsx\"\n",
        "        with pd.ExcelWriter(excel_file, engine='xlsxwriter') as writer:\n",
        "            df.to_excel(writer, sheet_name='Data', index=False)\n",
        "\n",
        "            # Add summary sheets\n",
        "            numeric_df.describe().to_excel(writer, sheet_name='Numeric Summary')\n",
        "            if not categorical_df.empty:\n",
        "                pd.concat([\n",
        "                    df[col].value_counts(dropna=False).rename(col)\n",
        "                    for col in categorical_df.columns\n",
        "                ], axis=1).to_excel(writer, sheet_name='Category Counts')\n",
        "\n",
        "            # Formatting\n",
        "            workbook = writer.book\n",
        "            worksheet = writer.sheets['Data']\n",
        "            header_format = workbook.add_format({\n",
        "                'bold': True,\n",
        "                'text_wrap': True,\n",
        "                'fg_color': '#2a3f5f',\n",
        "                'font_color': 'white',\n",
        "                'border': 1\n",
        "            })\n",
        "\n",
        "            for col_num, value in enumerate(df.columns.values):\n",
        "                worksheet.write(0, col_num, value, header_format)\n",
        "\n",
        "            # Auto-adjust columns\n",
        "            for i, col in enumerate(df.columns):\n",
        "                max_len = max((df[col].astype(str).map(len).max(), len(str(col)))) + 2\n",
        "                worksheet.set_column(i, i, min(max_len, 50))\n",
        "\n",
        "        print(f\"✓ Excel file saved as: {excel_file}\")\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"ℹ️ Excel export requires xlsxwriter. Install with: !pip install xlsxwriter\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Excel export failed: {str(e)}\")\n",
        "\n",
        "# Usage example\n",
        "# display_and_export_dataset(df_clean, num_rows=10, export_name=\"medical_data\")"
      ],
      "metadata": {
        "id": "Q7zOaoQbyFlU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}